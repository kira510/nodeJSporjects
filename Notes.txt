esWhat is Node.js?
  Before node, JS could not be used as a general purpose language. Node uses V8 internally.
  Its a javascript runtime built on Chrome's V8 javascript engine. Hence we can now use JS outside of the
  browser to build webservers that can access the file system and the database.
  To conclude , node js helps us use JS on server side programming.

  Chrome and node cannot read the JS code so they send the code to V8 engine and get back the results
  which can be understood by them.

  V8 is written in C++ due to which chrome and node are written majorly in C++ for easy binding. So when you run
  something like document.querySelector on chrome, at runtime a C++ function does this job underneath.
  Similarly, fs.readFile or os.platform run in node.js will be run by some C++ function underneath at runtime.

  => node
    > *repl where you can run code (read eval print loop)*
    > window
    > global
    > document
    > process
    > process.exit()

  Window is not defined for node instead we have global, why is that?
  Cause chrome works with a window and node does not and similarly global is not defined on brower. So is document
  with chrome which is not defined on node.
  Similar to document, here we have process.

Why to Use nodejs?
  Nodejs uses an event-driven, non-blocking I/O model that makes it lightweight and efficient.
  Node.js' package ecosystem , npm, is the largest ecosystem of open source libraries in the world.
    --> Non-blocking I/O: Any operation involving comunication with outside world are I/O operations like accessing the DB,
    the file syatem or getting some data from a server. What non-blocking I/O means that when nodejs is waitng for I/O
    operations, code execution can continue.
    --> Event-driven: Callbacks run after an event is complete or an event is fired, eg: I/O operations
    --> npm is node package manager, a tool that was installed when you installed node on your system. npm is the world's
    largest software registry.


Reading Command line data
  We always execute js files as node. So its basically command that you can optimise your js script to the way a shell script
  behaves, like give options, commands etc.
  Each command will have a set of options it needs and a handler.
        const yargs = require('yargs');
        console.log(process.argv)
        console.log(yargs.argv)

        OUTPUT-
          [ '/Users/kirankumar/.nvm/versions/node/v11.11.0/bin/node',
            '/Users/kirankumar/Documents/Tutorials/JS/NODE_JS/Andrew_mead/Project/notes-app/yargs',
            'read',
            '--title=hi' ]
          { _: [ 'read' ], title: 'hi', '$0': 'yargs' }

  As you can see in above code, we have process and yargs to get the command and options that were passed.

  PROCESS: The process object is a global that provides information about, and control over, the current Node.js process (https://nodejs.org/api/process.html)
  YARGS: A package that helps us parse the inputs , you can see above how it helps. If you use process then you must write your own parser.


DEBUGGING
  Its extremely simple,
    1. add a 'debugger' in your code
    2. run with inspect, which will open a debig console. "debug>"
            node inspect app.js add --title="wbdwehd" --body="third"
    3. Head over to chrome://inspect ,which opens the devices page and you know the rest.
    4. Also add the folder and give access to your folder in chrome to vide all the folder contents.
    6. After debugging, you can rerun the same debugger again.
            debug> restart
    7. Run (Ctrl + c) twice to end debugger.


Asynchronous Node.js (chapter 30)
    Call Stack, Node APIs, event loops ?
    JS is synchronous. Each line gets added to the call stack and gets executed, the asynchronous stuff like setTimout moves to the Node APIs
    stack whenre it starts executing in parallel (registering an event with Node APis).
    NODE APIS: DOM evnts, rest api calls, DB opearations
    After the event in  is complete, the node api pushed the completed result to event loop.
    Event loop each time checks if the call stack is empty, when its empty it will push the result from the callback queue to the call stack.
    Thats it.
    NOTE: Only after call stack is empty, the stuff in event loop gets executed.


REQUEST vs HTTP/HTTPS modules
    Why do we prefer to use external packages like request or axios or es6 fetch, casue this helps in request management very easy unlike the
    node.js HTTP or HTTPS module.
    In https module, response is received multiple times as abuffer and we must construct the data out of it. Too much code to write.


Hello Express JS
  1. Express JS
     Exports a function express that can be used to create an app.
          const app = express();
  2. app.use
     This works like app.get and also can be used to server static files.
          app.use(path, callbacks)
      It takes multiple callbacks that are expected sequetially unless you call next in one of them.
  3. express.static
     Method used to serve static files. It takes in a path which can be constructed using the path module exposed by nodejs.
          app.use(express.static(path.join(__dirname, '../public')));
      __dirname is a build in variable that gives present directory where it is run from.
      __filename : as simple as it is.
  4. app.listen
     It creates an http server that listens on the port you specify and takes a callbak function that gets called upon
     server creation.
  5. app.set
     This is usually used to set name to a value, set(name, value)
     ex:     app.set('view engine', hbs)
     This tells express that from now on it must use hbs to render from views. By default, hbs looks for the view files from
     the view folder in the home directory.
     Note that since we have added the static route, any path access within hbs file automatically looks for it in public folder.
     HBS is templating engine of handlebars for express.
  6. res.render(view [, locals] [, callback])
     view: a string that is the file path of the view file to render. This can be an absolute path, or a path relative to the views setting. If the path does not contain a file extension,
            then the view engine setting determines the file extension
     locals: an object whose properties define local variables for the view.
     NOOOOTE: the reason we use template engine like hbs is cause we can pass the dynamic varaibles.
  7. Partials
    HBS partials help us to share a web component across files. Also syntax is quite simple.
    This commit will show you how simple the syntax is.
  8. Styling
    We are using flex box to contruct our site, which is good learning for css.
  9. Restart Nodemon
     => nodemon src/app.js -e js,hbs
     By default, nodemon detects only the changes done on js files so make it listen to changes on hbs files also.

Connecting UI with Backend
  1. We simply add a form with input and button
  2. Register an event listner on the form and make a request to the localhost when
     the event is fired.
  3. FETCH
     This is a browser side interface to make requests which can run only in the browser.
     Note that we cannot make requests without CORS headers from the browser instead we have
     to call via our backend express server as you can see in this commit.


DEPLOYING with heroku
  1. https://devcenter.heroku.com/articles/git
     Set up a remote repo on the heroku and push the code there and it will start up.
     It will look for nodejs apps with package.json and tun "npm start"

SQL vs NoSQL
  1. SQL: data stored as table, ie in the from fo rows
     NoSQL: data stored as collection (array of json), i.e as documents.
  2. Individual items are stored as column in rows
     Each individual item is called field.

Setup MongoDB for local
  1. Download the mongodb server and move it to your home directory. https://www.mongodb.com/download-center/community
  2. Create a folder mongodb-data near it to save the data in there.
  3. Start the server:
      --> mongodb-server/bin/mongod --dbpath=/Users/kirankumar/mongodb-data
  4. Robo 3T
     GUI for MongoDB with embedded shell (https://robomongo.org/)
     Download this and install in your Mac
  5. You will need a driver to connect to database and perfrom CRUD operations,
     https://docs.mongodb.com/ecosystem/drivers/node/
     http://mongodb.github.io/node-mongodb-native/3.2/api/
  6. Install the mongodb nodejs driver, https://github.com/mongodb/node-mongodb-native
     --> npm install mongodb@3.1.10

Connecting to mongoddb,
  (please note these function can be used with promise or with callback, you know why we prefer promise.)
  1. Code looks like,
        MongoClient.connect(connectionURL, { useNewUrlParser: true }, (error, client) => {
          if (error) {
              return console.log('Unable to connect to database!');
          }

          console.log('Connected correctly!');
        });
    useNewUrlParser is used to parse connectionURL peoperly. It receives a callback function which implies
    that this is an asynchronous operation. And NOTE that, more than one connection is opened when we write
    this code.
    useFindAndModify: false; https://mongoosejs.com/docs/deprecations.html (used to prevent deprecation warnings on some methods)

    The client in the above callback is of type MongoClient, which has a method db to get the db.
    Use this db to get a collection and perfrom CRUD operations on it. Docs is your friend here.
        const db = client.db('task-manager');
        const taskCollection = db.collection('tasks');
        taskCollection.insertMany([>json array], (error, results) => {});

  2. ObjectId
      DOCS:  http://mongodb.github.io/node-mongodb-native/3.2/api/ObjectID.html
             https://docs.mongodb.com/manual/reference/method/ObjectId/
      Mongodb also provides ObjectId class that can be used to generate an id.
          const id = new ObjectId();
          console.log(id.id); //buffer string (bytes)
      NOTE: Mongodb is defensively programmed, even if you dont give new, mongodb adds it.
      The id is stored in the form of an ObjectID, what you see in Robot is a function ObjectId taking
      the id in string value which is just a visual representation for us.
  3. Read operation
    a. findOne:  returns an object, takes a query.
        If there are multiple, returns the first one.
    b. find:  returns a Cursor (http://mongodb.github.io/node-mongodb-native/3.2/api/Cursor.html)
       Use toArray, count, map, limit and all to make your query as you want.
  4. Update operation
    This is quite tricy, same as before but you have to provide additinal update options to update the
    data, mainly the update opeartors, the second link below will help you.
    Docs is your friend.
    https://docs.mongodb.com/manual/reference/method/db.collection.updateOne/#db.collection.updateOne
    https://docs.mongodb.com/manual/reference/operator/update/
    https://mongodb.github.io/node-mongodb-native/3.3/api/Collection.html#updateMany
  5. Delete
    Well nothing to say, you know it all.

Mongoose
  In terms of Node.js, mongodb is the native driver for interacting with a mongodb instance and mongoose
  is an Object modeling tool for MongoDB.

  Mongoose is built on top of the MongoDB driver to provide programmers with a way to model their data.
  Using Mongoose, a user can define the schema for the documents in a particular collection. It provides a
  lot of convenience in the creation and management of data in MongoDB. On the downside, learning
  mongoose can take some time, and has some limitations in handling schemas that are quite complex.

  However, if your collection schema is unpredictable, or you want a Mongo-shell like experience inside
  Node.js, then go ahead and use the MongoDB driver. It is the simplest to pick up. The downside here is
  that you will have to write larger amounts of code for validating the data, and the risk of errors is higher.

Using Mongoose
  1. Install it as usually
    => npm install mongoose
  2. Require it and use to connect it to a db,
    mongoose.connect(<url>, {options}) => returns a promise
    Two mandatory options to explore and include as options, useNewUrlParser and useCreateIndex.
  3. Use model to define the structure of document in a collection,
      const Task = mongoose.model(<collection name>, <schema>);
    Schema is just a json object that defines the fields. Type of the field and also we canset up
    validation. Some are available as inbuild options otherwise we can write custom using validate
    function.
    docs: --> https://mongoosejs.com/docs/schematypes.html , https://mongoosejs.com/docs/models.html
    Validator: -> https://github.com/validatorjs/validator.js
    Validation: https://docs.mongodb.com/manual/core/schema-validation/#specify-validation-rules
  4. Use the famous npm validator package to write validation, reduces your code and errors.
  5. Create a document and save it in the collection,
      const task1 = new Task({required_fields});
      task1.save();
  Checkout /src/db/maongoose.js for examples.

Creating and using end points
  1. set express to use express.json(), otherwise the request body will be undefined.
     app.use(express.json());
  2. A simple app.post or app.get method will help you create an endpoint,
      app.post('<ulr to match>', cb(req, res) {...})
  3. Callback takes req and res, make sure you send a response and with appropriate code.
  4. Select appropriate code from,
     --> https://httpstatuses.com/

Perfroming CRUD operations on Mongoose models
  1. Refer to https://mongoosejs.com/docs/api.html#Model

Update endpoint
  We can use post but patch seems to give more meaning to updating some document form the db.
      app.patch
  When we need to update a user, we need to first check if the field recieved from request can be updated if
  it cant then nothing happens cause findByIdandUpdate will not do anything.
        const user = await Users.findByIdAndUpdate({ _id: req.params.id }, req.body, {
            new: true,
            runValidators: true
        });
  So the below checks are done,
    1. Check if the field can be updated
    2. try to find the user by id and update
    3. set oprions new and runValidators to true, otherwise the user output will be the original one before update without any
       validation done on it.
    4. check if an user was returned for that id, findByIdandUpdate does not throw error if it doesn't find any data,
       instead it returns null.
    5. Handle catch

Mongoose middleware
  Middleware allows you to register some code to run before or after a lifecycle event for your model.
  The example below calls pre with the 'save' lifecycle event. This registers a function to run just before users are saved,
        userSchema.pre('save', async function (next) {
          console.log('Pre called!');
          let user = this;

          if (user.isModified('password')) {
            user.password = await bcrypt.hash(user.password, 8);
          }

          next();
        });
  The pre will be called only if you use the save method directly on the model, using findByIdAndUpdate or any fucntion that
  does direct operation directly runs on the DB due to which we need to provide runValidator and new option.
  DOCS: https://mongoosejs.com/docs/middleware.html

JWT
  DOCS: https://github.com/auth0/node-jsonwebtoken
  Json web token is basically a token that you generate which is used for authentication.
      const token = jwt.sign({ _id: '12345' }, 'mysecretkey', { expiresIn: '10s'});
      const payload = jwt.verify(token, 'mysecretkey');
  Extremely easy to use.
  The 'sign' method takes the payload and a secret to generate a token. Ex:
    eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfaWQiOiIxMjM0NSIsImlhdCI6MTU2Mjc4MzUzMCwiZXhwIjoxNTYyNzgzNTQwfQ.j47U0kFeUvuegpBevgzc8SI95wGo9JKY40TAK00GWqQ
  The token has three parts separated by period,
      1. first part specifies the type and the algorithm used. // {"alg":"HS256","type":"JWT"}
      2. second one has the payload with the timestamp when it was created. //{"_id":"12345","iat":1562783530,"exp":1562783540}
      3. signature which is used to verify the token.
  The first two are Base64 encoded, you can decode them from https://www.base64decode.org/ .

Login/logout and other requests
  When user logs in, our middleware will find that particular user and creates a JWT token for him which is sent back along with the response.
  Making ither request:
  On UI side we probably store this in local storage and the we add this as authorization header for each request.
  Header,
       Authorization" : "Beared <token>"
  These requests must be passed into and auth middleware where we verify the token and upon success, we store the token and
  the user in the request object.

Hiding Private data
  When we send the user data, res.send({ user });
  JSON.stringfy is called on the user data which internally cals the toJSON function so overriding this function can help us hide important
  data, EX:
      userSchema.methods.toJSON = function () {
        const user = this;
        const userObject = user.toObject();

        delete userObject.password;
        delete userObject.tokens;

        return userObject;
      };

Relating two models
  There are two ways to link two models, first way is to store the object id one of them in other and add the reference model.
  Where type must be specified as an ObjectID for which we need to use, mongoose.Schema.Types.ObjectId
      Ex: owner: {
            type: mongoose.Schema.Types.ObjectId,
            required: true,
            ref: 'User'
          }

  Now to link user to the tasks , we can save array of tasks into user but instead we can add it as virtual property.
      userSchema.virtual('tasks', {
        ref: 'Task',
        localField: '_id',
        foreignField: 'owner'
      })

  Then we can populate the tasks field in user or the owner field in either of the two using the populate method.
      await user.populate('tasks').execPopulate();
        This will add a tasks field to user that needs to be accessed separately via user.tasks, doing
            res.send(user);   // will just send the user object without tasks so you must,
            res.send(user.tasks);
  Similarly to fetch owner details on task you must do the below,
      await task.populate('owner').execPopulate();
      console.log(task.owner);

  DOCS: https://mongoosejs.com/docs/api/virtualtype.html

Filtering and pagination
  The below code itself explains a lot. Construct a match object with fields you want it to match. You can use find also but this
  is also cool.
        await req.user.populate({
            path: 'tasks',
            match,
            options: {
                limit: parseInt(req.query.limit),
                skip: parseInt(req.query.skip)
            }
        }).execPopulate()
  Docs: https://mongoosejs.com/docs/populate.html#query-conditions
        https://mongoosejs.com/docs/api.html#model_Model.find

Sorting
  What does a request look like?
    request: /tasks?sortBy=createdAt:desc
        if (req.query.sortBy) {
          const parts = req.query.sortBy.split(':');
          sort[parts[0]] = parts[1] === 'desc' ? -1 : 1;
        }
        await req.user.populate({
            path: 'tasks',
            match,
            options: {
                limit: parseInt(req.query.limit),
                skip: parseInt(req.query.skip),
                sort
            }
        }).execPopulate()

Uplading/saving/deleteing files
  We use a quite popular package called MULTER. It can be passsed as a middleware to a route to maange file uploads.
  It also can be used for validation which is very helpful.
      const upload = multer({
          //dest: path.join(__dirname, '..', 'avatars'),
          limits: {
              fileSize: 1000000
          },
          fileFilter(req, file, cb) {
              if (!file.originalname.match(/\.(png|jpg|jpeg)$/)) {
                  return cb(new Error('Please provide jpg, jpeg or png'));
              }

              cb(undefined, true)
          },
          preservePath: true
      })

  If you just specify a destination like images then an images folder is created in the main directory where src is present.
  Docs that will help you use multer: https://github.com/expressjs/multer#readme
  Use this as a middleware by calling single method on upload.
  Then we can use SHARP to resize and also convert all of them to the type of file you need.
  Deleting:
      req.user.avatar = undefined
      await req.user.save();
    When you make a filed undefined then this filed is removed from the database.

  NOTE: While sending the file back you must set the header to have to content-type to image/png,
          res.set('Content-Type', 'image/png').send(user.avatar)

Sending Emails
  sendgrid itself provides a nodejs package that you can use,
      @sendgrid/mail
  It has quite good documentation that you can use.

Storing secret keys
  To store the secret key, use an env file like i have attached (/src/config/dev.env), please note that this must not be pushed to github.
  Instead store it in password safe and provide it to devs when needed and add to git.ignore so you dont commit it by mistake.
  docs: https://app.sendgrid.com/guide/integrate/langs/nodejs
  A package we use to read this file is,
      => npm i env-cmd --save-dev
  And add this to you nmp scripts as,
      "dev": "env-cmd ./src/config/dev.env nodemon src/index.js"
  Now your secrets are safe.








